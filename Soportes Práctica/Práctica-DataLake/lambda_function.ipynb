{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRs4VZ3hGS6G"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "\n",
        "# Definir nombres del bucket y archivos\n",
        "BUCKET_NAME = \"data-lake-x\"\n",
        "RAW_FILE = \"bronze/clientes.csv\"\n",
        "PROCESSED_FILE = \"silver/clientes_limpios.csv\"\n",
        "\n",
        "# Crear cliente S3\n",
        "s3 = boto3.client(\"s3\")\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "    try:\n",
        "        print(\"Iniciando procesamiento de archivos en S3...\")\n",
        "\n",
        "        # Verificar si el bucket existe\n",
        "        s3.head_bucket(Bucket=BUCKET_NAME)\n",
        "        print(f\"El bucket {BUCKET_NAME} existe.\")\n",
        "\n",
        "        # Descargar archivo desde S3\n",
        "        response = s3.get_object(Bucket=BUCKET_NAME, Key=RAW_FILE)\n",
        "        data = response[\"Body\"].read().decode(\"utf-8\").splitlines()\n",
        "\n",
        "        # Procesar líneas: reemplazar \"F\" y \"M\", eliminar filas vacías\n",
        "        cleaned_data = []\n",
        "        for line in data:\n",
        "            columns = line.split(\",\")  # Separar por columnas\n",
        "\n",
        "            # Verificar si alguna columna está vacía\n",
        "            if \"\" in columns:\n",
        "                continue  # Omitir la fila si tiene una celda vacía\n",
        "\n",
        "            # Reemplazar valores en la columna de género\n",
        "            updated_columns = [col.replace(\"F\", \"Femenino\").replace(\"M\", \"Masculino\") for col in columns]\n",
        "            cleaned_data.append(\",\".join(updated_columns))\n",
        "\n",
        "        # Convertir de nuevo a string\n",
        "        output_data = \"\\n\".join(cleaned_data)\n",
        "\n",
        "        # Subir el nuevo archivo procesado a S3 en la carpeta \"silver\"\n",
        "        s3.put_object(Bucket=BUCKET_NAME, Key=PROCESSED_FILE, Body=output_data)\n",
        "\n",
        "        print(f\"Archivo procesado subido a {PROCESSED_FILE}\")\n",
        "\n",
        "        return {\n",
        "            \"statusCode\": 200,\n",
        "            \"body\": f\"Archivo procesado y guardado en {PROCESSED_FILE}\"\n",
        "        }\n",
        "\n",
        "    except s3.exceptions.NoSuchBucket:\n",
        "        print(f\"Error: El bucket {BUCKET_NAME} no existe.\")\n",
        "        return {\n",
        "            \"statusCode\": 404,\n",
        "            \"error\": f\"El bucket {BUCKET_NAME} no existe. Verifica el nombre y la región.\"\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error procesando archivo: {str(e)}\")\n",
        "        return {\n",
        "            \"statusCode\": 500,\n",
        "            \"error\": str(e)\n",
        "        }\n"
      ]
    }
  ]
}